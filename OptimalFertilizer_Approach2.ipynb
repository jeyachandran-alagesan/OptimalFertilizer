{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import configs and Dataseta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "PROJECT_HOME = os.getcwd()\n",
    "# Paths\n",
    "\n",
    "TRAIN_PATH = PROJECT_HOME+\"/data/train_kaggle.csv\"\n",
    "TEST_PATH  = PROJECT_HOME+\"/data/test_kaggle.csv\"\n",
    "ORIGINAL_PATH = PROJECT_HOME+\"/data/train_ieee.csv\"\n",
    "    \n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "original = pd.read_csv(ORIGINAL_PATH)\n",
    "submission_df = test.copy()\n",
    "train.shape, test.shape, original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "FOLDS = np.zeros(len(train))\n",
    "skf = StratifiedKFold(n_splits=NFOLDS, random_state=42, shuffle=True)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train, train['Fertilizer Name'])):\n",
    "    FOLDS[test_index]=i\n",
    "train['fold'] = FOLDS\n",
    "\n",
    "FOLDS = np.zeros(len(original))\n",
    "skf = StratifiedKFold(n_splits=NFOLDS, random_state=42, shuffle=True)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(original, original['Fertilizer Name'])):\n",
    "    FOLDS[test_index]=i\n",
    "original['fold'] = FOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Encoding and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['id'], inplace=True)\n",
    "test.drop(columns=['id'], inplace=True)\n",
    "\n",
    "train = train.rename(columns={'Temparature': 'Temperature'})\n",
    "test  = test.rename(columns={'Temparature': 'Temperature'})\n",
    "original  = original.rename(columns={'Temparature': 'Temperature'})\n",
    "\n",
    "cat_cols = [col for col in test.select_dtypes(include=['object', 'category']).columns]\n",
    "for col in cat_cols:\n",
    "    label_enc = LabelEncoder()\n",
    "    train[col] = label_enc.fit_transform(train[col])\n",
    "    test[col] = label_enc.transform(test[col])\n",
    "    original[col] = label_enc.transform(original[col])\n",
    "\n",
    "target_label_enc = LabelEncoder()\n",
    "train[\"Fertilizer Name\"] = target_label_enc.fit_transform(train[\"Fertilizer Name\"])\n",
    "original[\"Fertilizer Name\"] = target_label_enc.transform(original[\"Fertilizer Name\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comp_data'] = 0\n",
    "test['comp_data'] = 1\n",
    "original['comp_data'] = 2\n",
    "raw = pd.concat([train, test, original]).reset_index(drop=True)\n",
    "print(raw.shape)\n",
    "\n",
    "\n",
    "numerical_features = ['Temperature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "for col in numerical_features:\n",
    "    raw[col+'_cat'] =  raw[col].astype(str).astype('category')\n",
    "\n",
    "numerical_features = ['Soil Type', 'Crop Type']\n",
    "for col in numerical_features:\n",
    "    raw[col] =  raw[col].astype(str).astype('category')\n",
    "\n",
    "train = raw.loc[raw['comp_data']==0].reset_index(drop=True)\n",
    "test = raw.loc[raw['comp_data']==1].reset_index(drop=True)\n",
    "original = raw.loc[raw['comp_data']==2].reset_index(drop=True)\n",
    "del raw\n",
    "test['comp_data'] = 0\n",
    "original['comp_data'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Engineerig to generate Derived parameters and randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_1 = 51*19\n",
    "RANDOM_2 = 33\n",
    "RANDOM_3 = 37*29\n",
    "RANDOM_4 = 23\n",
    "RANDOM_5 = 33*21\n",
    "RANDOM_6 = 16\n",
    "\n",
    "RANDOM_7 = 7\n",
    "RANDOM_8 = 11\n",
    "\n",
    "train[\"Derived_1\"]   = train['Nitrogen']*RANDOM_1   +train['Potassium']*RANDOM_2   +train['Phosphorous']\n",
    "test[\"Derived_1\"]    = test['Nitrogen']*RANDOM_1    +test['Potassium']*RANDOM_2    +test['Phosphorous']\n",
    "original[\"Derived_1\"]= original['Nitrogen']*RANDOM_1 +original['Potassium']*RANDOM_2 +original['Phosphorous']\n",
    "\n",
    "train[\"Derived_2\"]   = train['Nitrogen'] +train['Potassium']*RANDOM_3 +train['Phosphorous']*RANDOM_4\n",
    "test[\"Derived_2\"]    = test['Nitrogen']  +test['Potassium']*RANDOM_3 +test['Phosphorous']*RANDOM_4\n",
    "original[\"Derived_2\"]= original['Nitrogen'] +original['Potassium']*RANDOM_3 +original['Phosphorous']*RANDOM_4\n",
    "\n",
    "train[\"Derived_3\"]   = train['Nitrogen']*RANDOM_6 +train['Potassium'] +train['Phosphorous']*RANDOM_5\n",
    "test[\"Derived_3\"]    = test['Nitrogen']*RANDOM_6 +test['Potassium'] +test['Phosphorous']*RANDOM_5\n",
    "original[\"Derived_3\"]= original['Nitrogen']*RANDOM_6 + original['Potassium'] + original['Phosphorous']*RANDOM_5\n",
    "\n",
    "train[\"Derived_4\"] = train['Soil Type'].astype(int).values + train['Crop Type'].astype(int).values*RANDOM_7 + ((train[\"Derived_1\"] + train[\"Derived_2\"] + train[\"Derived_3\"]) / 3)\n",
    "test[\"Derived_4\"] = test['Soil Type'].astype(int).values + test['Crop Type'].astype(int).values*RANDOM_7 + ((test[\"Derived_1\"] + test[\"Derived_2\"] + test[\"Derived_3\"]) / 3)\n",
    "original[\"Derived_4\"] = original['Soil Type'].astype(int).values + original['Crop Type'].astype(int).values*RANDOM_7 + ((original[\"Derived_1\"] + original[\"Derived_2\"] + original[\"Derived_3\"]) / 3)\n",
    "\n",
    "train[\"Derived_5\"] = train['Soil Type'].astype(int).values*RANDOM_8 + train['Crop Type'].astype(int).values + ((train[\"Derived_1\"] + train[\"Derived_2\"] + train[\"Derived_3\"]) / 3)\n",
    "test[\"Derived_5\"] = test['Soil Type'].astype(int).values*RANDOM_8 + test['Crop Type'].astype(int).values + ((test[\"Derived_1\"] + test[\"Derived_2\"] + test[\"Derived_3\"]) / 3)\n",
    "original[\"Derived_5\"] = original['Soil Type'].astype(int).values*RANDOM_8 + original['Crop Type'].astype(int).values +  ((original[\"Derived_1\"] + original[\"Derived_2\"] + original[\"Derived_3\"]) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Defination to evaluvate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def map3(predicted: np.ndarray, labels: np.ndarray) -> float:\n",
    "    pred = np.argsort(-1*predicted, 1)\n",
    "    \n",
    "    p0 = (labels == pred[:, 0])\n",
    "    p1 = (labels == pred[:, 1])\n",
    "    p2 = (labels == pred[:, 2])\n",
    "    \n",
    "    return float(np.mean(p0/1 + p1/2 + p2/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Feature Encoding and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in train.columns if f not in ['fold', 'target', 'grp', 'Fertilizer Name', 'ids']]\n",
    "train[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Feature Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 100000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_class\": 7,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_weight\": 0.00024,\n",
    "    \"subsample\": 0.74,\n",
    "    \"colsample_bytree\": 0.39,\n",
    "    \"gamma\": 0.48,\n",
    "    \"reg_alpha\":0.027,\n",
    "    \"reg_lambda\": 0.0002,\n",
    "    'max_bin': 64,\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"tree_method\": \"hist\",  # Faster and memory-efficient\n",
    "    \"enable_categorical\": True,\n",
    "    \"device\" :\"cuda\"\n",
    "}\n",
    "\n",
    "NBAGS = 2\n",
    "ytrain = np.zeros( (len(train), 7) )\n",
    "ytest = np.zeros( (len(test), 7) )\n",
    "\n",
    "# Pre-convert original dataset for faster concatenation\n",
    "original_X = original[features]\n",
    "original_y = original['Fertilizer Name']\n",
    "\n",
    "# Pre-build test DMatrix (unchanged across folds/bags)\n",
    "dtest = xgb.DMatrix(test[features], enable_categorical=True)\n",
    "\n",
    "for fold in range(NFOLDS):\n",
    "    print(f\"Fold {fold}\")\n",
    "\n",
    "    # Boolean masks for train/valid\n",
    "    ind_train = train['fold'] != fold\n",
    "    ind_valid = train['fold'] == fold\n",
    "\n",
    "    X_valid = train.loc[ind_valid, features]\n",
    "    y_valid = train.loc[ind_valid, 'Fertilizer Name']\n",
    "\n",
    "    # Validation DMatrix created once per fold\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)\n",
    "\n",
    "    # Cached training data for this fold (to reduce repeated slicing)\n",
    "    fold_X = train.loc[ind_train, features]\n",
    "    fold_y = train.loc[ind_train, 'Fertilizer Name']\n",
    "\n",
    "    for bag in range(NBAGS):\n",
    "\n",
    "        # Randomize parameters for this bag\n",
    "        params['seed'] = (bag + 1) * 11\n",
    "        params['learning_rate'] = np.random.normal(0.005, 0.01)\n",
    "        params['colsample_bytree'] = np.random.normal(0.39, 0.005)\n",
    "        params['subsample'] = np.random.normal(0.74, 0.005)\n",
    "\n",
    "        # Random oversampling (add K2 copies of original data)\n",
    "        K2 = np.random.randint(5, 8)\n",
    "\n",
    "        # Fast concat using a list (Pandas optimizes this well)\n",
    "        X_train = pd.concat(\n",
    "            [fold_X] + [original_X] * K2,\n",
    "            axis=0,\n",
    "            ignore_index=True\n",
    "        )\n",
    "        y_train_label = pd.concat(\n",
    "            [fold_y] + [original_y] * K2,\n",
    "            axis=0,\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Create training DMatrix\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train_label, enable_categorical=True)\n",
    "\n",
    "        # Train model\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            99999,\n",
    "            evals=[(dvalid, \"validation\")],\n",
    "            verbose_eval=False,  \n",
    "            callbacks=[xgb.callback.EarlyStopping(rounds=100, save_best=True)],\n",
    "        )\n",
    "\n",
    "        # OOF predictions\n",
    "        preds_valid = model.predict(dvalid)\n",
    "        ytrain[ind_valid] += preds_valid / NBAGS\n",
    "\n",
    "        # Print score for this bag\n",
    "        print(f\"Fold {fold} | Bag {bag} | MAP@3 = {map3(preds_valid, y_valid.values):.6f}\")\n",
    "\n",
    "        # Test predictions (averaged)\n",
    "        ytest += model.predict(dtest) / (NFOLDS * NBAGS)\n",
    "\n",
    "\n",
    "score = map3(ytrain, train['Fertilizer Name'].values)\n",
    "print(score)\n",
    "################\n",
    "top_3_preds = np.argsort(ytest, axis=1)[:, -3:][:, ::-1]\n",
    "top_3_labels = target_label_enc.inverse_transform(top_3_preds.ravel()).reshape(top_3_preds.shape)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': submission_df['id'],\n",
    "    'Fertilizer Name': [' '.join(row) for row in top_3_labels]\n",
    "})\n",
    "submission.to_csv(\"Approach2.csv\", index=False)\n",
    "print(\"âœ… Submission file saved as 'Approach2.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12184666,
     "sourceId": 91717,
     "sourceType": "competition"
    },
    {
     "datasetId": 7269189,
     "sourceId": 11592231,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8729101,
     "sourceId": 13720137,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
